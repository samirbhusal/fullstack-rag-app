import os
import time
from pinecone import Pinecone, ServerlessSpec
from dotenv import load_dotenv
from pathlib import Path
from langchain.chains import RetrievalQA
from langchain_groq import ChatGroq
from langchain_huggingface import HuggingFaceEndpointEmbeddings
from langchain_pinecone import PineconeVectorStore
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain.prompts import PromptTemplate

load_dotenv()

# Configuration
INDEX_NAME = "rag-chatbot"
EMBEDDING_DIMENSIONS = 384

PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")

def get_pinecone_client():
    return Pinecone(api_key=PINECONE_API_KEY)


if not PINECONE_API_KEY:
    print("‚ùå ERROR: PINECONE_API_KEY is missing from environment!")
else:
    print("‚úÖ PINECONE_API_KEY found.")

embeddings = HuggingFaceEndpointEmbeddings(
    model="sentence-transformers/all-MiniLM-L6-v2",
    huggingfacehub_api_token=os.getenv("HUGGINGFACE_API_KEY")
)

custom_prompt_template = """
You are a helpful AI assistant. Answer the question based on the context below.

Context:
{context}

Question: 
{question}

Instructions:
1. If the answer is found in the Context above, answer clearly and concisely.
2. If the Context does NOT contain the answer, strictly follow this format:
   - First, say: "‚ö†Ô∏è I couldn't find specific information about this in your uploaded documents."
   - Then, say: "However, based on my general knowledge, here is what I know:"
   - Finally, provide a helpful answer based on your own training.

Answer:
"""

PROMPT = PromptTemplate(
    template=custom_prompt_template, 
    input_variables=["context", "question"]
)

def ensure_index_exists():
    """
    Checks if the Pinecone index exists. If not, creates it.
    Returns True if ready, False if something failed.
    """
    pc = get_pinecone_client()
    existing_indexes = [i.name for i in pc.list_indexes()]
    
    if INDEX_NAME not in existing_indexes:
        print(f"‚ö†Ô∏è Index '{INDEX_NAME}' not found. Creating it now...")
        try:
            pc.create_index(
                name=INDEX_NAME,
                dimension=EMBEDDING_DIMENSIONS,
                metric="cosine",
                spec=ServerlessSpec(cloud="aws", region="us-east-1")
            )
            print("‚è≥ Waiting for index to initialize...")
            time.sleep(10)
            print("‚úÖ Index created successfully!")
        except Exception as e:
            print(f"‚ùå Failed to create index: {e}")
            return False
    return True

def add_to_knowledge_base(texts_list, api_key=None):
    if not texts_list:
        print("‚ùå Error: No text found in the input.")
        return "‚ö†Ô∏è Error: No readable text found."

    try:
        ensure_index_exists()
    except Exception as e:
        print(f"‚ùå Database Creation Failed: {e}")
        return f"‚ùå Database Error: {e}"

    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200, separators=["\n\n", "\n", " ", ""])
    docs = text_splitter.create_documents(texts_list)
    print(f"üìÑ Prepared {len(docs)} chunks for upload.")
    
    # --- DEBUGGING: Print a snippet of the text to ensure it's not empty ---
    print(f"   (Snippet: {docs[0].page_content[:100]}...)") 

    try:
        # 1. Upload to Pinecone
        print("üöÄ Sending to Pinecone...")
        PineconeVectorStore.from_documents(
            documents=docs, 
            embedding=embeddings, 
            index_name=INDEX_NAME
        )
        print("‚úÖ Upload command accepted.")
        
        # 2. Verification Loop
        print("‚è≥ Verification: Waiting for Pinecone to index data...")
        pc = Pinecone(api_key=PINECONE_API_KEY)
        index = pc.Index(INDEX_NAME)
        
        for attempt in range(15):  # Increased wait time slightly
            stats = index.describe_index_stats()
            count = stats['total_vector_count']
            if count > 1: # Logic check: Should be > 1 now (since we already have 1 debug record)
                print(f"‚úÖ Data verified! Vector count is now: {count}")
                return f"‚úÖ Success: {len(docs)} chunks indexed and ready."
            time.sleep(2)
            
        print("‚ö†Ô∏è Time-out waiting for Pinecone.")
        return "‚ö†Ô∏è Upload processed, but Pinecone is slow to update. Please wait 30s before searching."

    except Exception as e:
        # --- CRITICAL: PRINT THE ERROR TO TERMINAL ---
        print(f"\n‚ùå‚ùå‚ùå UPLOAD FAILED ‚ùå‚ùå‚ùå")
        print(f"Error Details: {str(e)}")
        import traceback
        traceback.print_exc()
        return f"‚ùå Upload Error: {str(e)}"

def query_knowledge_base(query_text, api_key=None):

    pc = get_pinecone_client()
    existing_indexes = [i.name for i in pc.list_indexes()]

    if INDEX_NAME not in existing_indexes:
        return "‚ö†Ô∏è Knowledge Base not found. Please upload a document to create it."

    # 2. Now we know it exists, we can safely connect
    index = pc.Index(INDEX_NAME)

    try:
        stats = index.describe_index_stats()
        if stats['total_vector_count'] == 0:
            return "‚ö†Ô∏è The Knowledge Base is empty. Please upload a document to get started."
    except Exception:
            # If we can't even get stats, the index probably doesn't exist yet
            return "‚ö†Ô∏è Knowledge Base not found. Please upload a document first."
    
    try:
        vectorstore = PineconeVectorStore.from_existing_index(
            index_name=INDEX_NAME,
            embedding=embeddings,
            text_key="text"
        )
    except Exception as e:
        return "‚ö†Ô∏è Connection Error: Could not connect to Pinecone."

    llm = ChatGroq(
        model="llama-3.3-70b-versatile",
        temperature=0,
        api_key=os.getenv("GROQ_API_KEY")
    )

    qa = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        return_source_documents=True,
        retriever=vectorstore.as_retriever(search_kwargs={"k": 3}),
        chain_type_kwargs={"prompt": PROMPT}
    )

    try:
        response = qa.invoke(query_text)
        return response["result"]
    except Exception as e:
        print(f"Query Error: {e}")
        return "‚ö†Ô∏è The Knowledge Base is empty or not found. Please upload a document first."


    